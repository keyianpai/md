---
title: "软件使用"
date: 2018-07-10T20:31:49+08:00
draft: false
---
# Modeling Industrial ADMET Data with Multitask Networks

- 多任务比单任务学习好
- 多任务学习中，从小数据集获益比大数据集大

# SMILES Enumeration as Data Augmentation for Neural Network Modeling of Molecules

# Boosting compound-protein interaction prediction by deep learning

- One molecule can however have multiple SMILES strings
- multiple SMILES represent the same molecule is explored as a technique for data augmentation
- Canonical SMILES is a unique way of writing a SMILES for a molecule,
- The model using the expanded dataset was moderately better at predicting the test set of either **enumerated or canonical SMILES**
> enantiomer （对应体，手性分子） aliphatic carbon （脂肪族碳）

# Sequence Models and Long-Short Term Memory Networks
- The first axis is the sequence itself, the second indexes instances in the mini-batch, and the third indexes elements of the input.
> 这里第一个轴应该是指最左边的那一维，比方说，矩阵的第一个轴的坐标表示第几行。里面举例句子 “The cow jumped” 的表示，每个单词就是一个sequence，用矩阵3行，每行所代表的那个向量就是一个单词。矩阵中间在插入一个维（也就是第二个轴），其坐标表示第几个句子（这个坐标取值个数决定了有几个句子，也即batch size），一个句子时第二个轴只能取一个值，同理，要只有一个单词，第一个轴也只能取一个值。

# Computational Modeling of β‑Secretase 1 (BACE-1) Inhibitors Using Ligand Based Approaches
>  Ligand 配体，Inhibitor 抑制剂， β-分泌酶1（BACE1）抑制剂，结合亲和力（IC50），quantitative−structure activity relationships (QSAR)， qualitative
classification (∼70% accuracy) and quantitative IC50 predictions (RMSE ∼ 1 log)

- The success of the 2D descriptor based machine learning approach when compared against the 3D field based technique pursued for hBACE-1 inhibitors provides a strong impetus for systematically applying such methods during the lead identification and optimization efforts for other protein families as well.
### RNN
$$h_t=\text{tanh}(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_{hh})$$
> Inputs: input, h_0
 - input of shape `(seq_len, batch, input_size)`
   - `input_size` – The number of expected features in the input x
 - h_0 of shape `(num_layers * num_directions, batch, hidden_size)`:tensor containing the initial hidden state for each element in the batch
   - `hidden_size` – The number of features in the hidden state h
   - `num_directions` - 1 or 2
   - `num_layers` – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results   

   > Outputs: output, h_n
    - output of shape `(seq_len, batch, hidden_size * num_directions)`
    - h_n of shape h_0

### LSTM
$$i_t,f_t,o_t,g_t,c_t=f_tc_{t-1}+i_tg_t
,h_t=o_t\text{tanh}(c_t)$$
毒性预测：准确率，SN，SP测试集都比训练集低的情况下怎么算得AUC值反而高，我是用预测的0/1向量与实际0/1向量算的
